{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from responsibly.dataset import AdultDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from os.path import join as os_join\n",
    "\n",
    "pd.set_option('display.max_rows', 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               State-gov\n",
       "1        Self-emp-not-inc\n",
       "2                 Private\n",
       "3                 Private\n",
       "4                 Private\n",
       "               ...       \n",
       "48836             Private\n",
       "48837             Private\n",
       "48839             Private\n",
       "48840             Private\n",
       "48841        Self-emp-inc\n",
       "Name: workclass, Length: 45222, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  education-num   race   sex  capital_gain  capital_loss  \\\n",
      "0   39             13  White  Male          2174             0   \n",
      "1   50             13  White  Male             0             0   \n",
      "2   38              9  White  Male             0             0   \n",
      "3   53              7  Black  Male             0             0   \n",
      "\n",
      "   hours_per_week native_country income_per_year         occupation  \\\n",
      "0              40  United-States           <=50K       Adm-clerical   \n",
      "1              13  United-States           <=50K    Exec-managerial   \n",
      "2              40  United-States           <=50K  Handlers-cleaners   \n",
      "3              40  United-States           <=50K  Handlers-cleaners   \n",
      "\n",
      "          workclass dataset  \n",
      "0         State-gov   train  \n",
      "1  Self-emp-not-inc   train  \n",
      "2           Private   train  \n",
      "3           Private   train  \n",
      "White                 38903\n",
      "Black                  4228\n",
      "Asian-Pac-Islander     1303\n",
      "Amer-Indian-Eskimo      435\n",
      "Other                   353\n",
      "Name: race, dtype: int64\n",
      "Male      30527\n",
      "Female    14695\n",
      "Name: sex, dtype: int64\n",
      "United-States                 41292\n",
      "Mexico                          903\n",
      "Philippines                     283\n",
      "Germany                         193\n",
      "Puerto-Rico                     175\n",
      "Canada                          163\n",
      "El-Salvador                     147\n",
      "India                           147\n",
      "Cuba                            133\n",
      "England                         119\n",
      "China                           113\n",
      "Jamaica                         103\n",
      "South                           101\n",
      "Italy                           100\n",
      "Dominican-Republic               97\n",
      "Japan                            89\n",
      "Guatemala                        86\n",
      "Vietnam                          83\n",
      "Columbia                         82\n",
      "Poland                           81\n",
      "Haiti                            69\n",
      "Portugal                         62\n",
      "Iran                             56\n",
      "Taiwan                           55\n",
      "Greece                           49\n",
      "Nicaragua                        48\n",
      "Peru                             45\n",
      "Ecuador                          43\n",
      "Ireland                          36\n",
      "France                           36\n",
      "Thailand                         29\n",
      "Hong                             28\n",
      "Cambodia                         26\n",
      "Trinadad&Tobago                  26\n",
      "Yugoslavia                       23\n",
      "Outlying-US(Guam-USVI-etc)       22\n",
      "Laos                             21\n",
      "Scotland                         20\n",
      "Honduras                         19\n",
      "Hungary                          18\n",
      "Holand-Netherlands                1\n",
      "Name: native_country, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xingzhiguo/miniconda3/lib/python3.8/site-packages/responsibly/dataset/adult/__init__.py:56: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n"
     ]
    }
   ],
   "source": [
    "adult_ds = AdultDataset()\n",
    "adult_ds._validate()\n",
    "sub_columns = ['age', 'education-num', 'race', 'sex','capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income_per_year', 'occupation', 'workclass', 'dataset']\n",
    "df_data = adult_ds.df.loc[:,sub_columns]\n",
    "print (df_data.head(4))\n",
    "df_country_gdp = pd.read_csv('../data/adult-dataset/gdp-pc.csv').loc[:, ['Country Name','1996']] # the dataset is from 1996\n",
    "for col in ['race', 'sex', 'native_country']:\n",
    "    print(df_data[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adult_ds.df['occupation'].value_counts()\n",
    "# adult_ds.df['occupation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "countries not presented in world bank: {'yugoslavia', 'taiwan', 'columbia', 'south'}\n"
     ]
    }
   ],
   "source": [
    "def _normalize_country_name(x):\n",
    "    x = \" \".join(str.lower(x).split('-'))\n",
    "    if x== \"trinadad&tobago\":\n",
    "        x = 'Trinidad and Tobago'\n",
    "    elif x == 'england' or x == 'scotland':\n",
    "        x = 'United Kingdom'\n",
    "    elif x == 'holand netherlands':\n",
    "        x = 'Netherlands'\n",
    "    elif x == 'hong':\n",
    "        x ='Hong Kong SAR, China'\n",
    "    elif x == 'laos':\n",
    "        x ='Lao PDR'\n",
    "    elif x == 'iran':\n",
    "        x ='Iran, Islamic Rep.'\n",
    "    elif x == 'outlying us(guam usvi etc)':\n",
    "        x ='United States'\n",
    "    return \" \".join(str.lower(x).split('-'))\n",
    "\n",
    "df_data['native_country'] = df_data['native_country'].apply(_normalize_country_name).to_list() \n",
    "df_country_gdp['Country Name'] = df_country_gdp['Country Name'].apply(_normalize_country_name).to_list()\n",
    "\n",
    "aset = set( df_country_gdp.dropna()['Country Name'].to_list())\n",
    "bset = set( df_data.loc[:,'native_country'].to_list())\n",
    "dff_set = bset - aset\n",
    "print ('countries not presented in world bank:',dff_set)\n",
    "df_data = df_data[~df_data['native_country'].isin(dff_set)]\n",
    "\n",
    "gdp_lut = df_country_gdp.dropna().set_index('Country Name').to_dict()['1996']\n",
    "\n",
    "df_data['gdp_pc'] = [gdp_lut[country] for country in df_data['native_country'].to_list()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age_feat (44961, 1) [17.] [90.]\n",
      "edu_feat (44961, 1) [1.] [16.]\n",
      "race_feat (44961, 5)\n",
      "sex_feat (44961, 1)\n",
      "capital_gain_feat (44961, 1)\n",
      "capital_loss_feat (44961, 1)\n",
      "hours_per_week_feat (44961, 1) [1.] [99.]\n",
      "gdp_pc_feat (44961, 1) [319.28631355] [39150.03963081]\n",
      "income_feat (44961, 1)\n",
      "race_white_black_feat (44961, 1)\n",
      "country_is_native_feat (44961, 1)\n",
      "occupation_managerial_feat (44961, 1)\n",
      "occupation_is_gov_feat (44961, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "age_feat = df_data['age'].to_numpy().reshape(-1,1)\n",
    "# print (age_feat.shape)\n",
    "min_max_scaler_age = preprocessing.MinMaxScaler()\n",
    "age_feat = min_max_scaler_age.fit_transform(age_feat)\n",
    "print ('age_feat',age_feat.shape, min_max_scaler_age.data_min_, min_max_scaler_age.data_max_)\n",
    "\n",
    "\n",
    "edu_feat = df_data['education-num'].to_numpy().reshape(-1,1)\n",
    "# print (edu_feat.shape)\n",
    "min_max_scaler_age = preprocessing.MinMaxScaler()\n",
    "edu_feat = min_max_scaler_age.fit_transform(edu_feat)\n",
    "print ('edu_feat',edu_feat.shape, min_max_scaler_age.data_min_, min_max_scaler_age.data_max_)\n",
    "\n",
    "\n",
    "def _race_encoder(x):\n",
    "    race_dict = {\n",
    "        \"White\":0,\n",
    "        \"Black\":1,\n",
    "        \"Asian-Pac-Islander\":2,\n",
    "        \"Amer-Indian-Eskimo\":3,\n",
    "        \"Other\":4\n",
    "    }\n",
    "    _feat = np.zeros(len(race_dict.keys()))\n",
    "    _feat[race_dict[x]] = 1\n",
    "    return _feat\n",
    "race_feat = [_race_encoder(_) for _ in df_data['race'].to_list()]\n",
    "race_feat = np.array(race_feat)\n",
    "print ('race_feat',race_feat.shape)\n",
    "\n",
    "\n",
    "\n",
    "def _gender_encoder(x):\n",
    "    gender_dict = {\n",
    "        \"Male\":1,\n",
    "        \"Female\":0,\n",
    "    }\n",
    "    return gender_dict[x]\n",
    "sex_feat = [_gender_encoder(_) for _ in df_data['sex'].to_list()]\n",
    "sex_feat = np.array(sex_feat).reshape(-1,1)\n",
    "print ('sex_feat',sex_feat.shape)\n",
    "\n",
    "capital_gain_feat = df_data['capital_gain'].to_numpy().reshape(-1,1)\n",
    "# print (edu_feat.shape)\n",
    "min_max_scaler_age = preprocessing.MinMaxScaler()\n",
    "capital_gain_feat = min_max_scaler_age.fit_transform(capital_gain_feat)\n",
    "print ('capital_gain_feat',capital_gain_feat.shape)\n",
    "\n",
    "capital_loss_feat = df_data['capital_loss'].to_numpy().reshape(-1,1)\n",
    "# print (edu_feat.shape)\n",
    "min_max_scaler_age = preprocessing.MinMaxScaler()\n",
    "capital_loss_feat = min_max_scaler_age.fit_transform(capital_loss_feat)\n",
    "print ('capital_loss_feat',capital_loss_feat.shape)\n",
    "\n",
    "\n",
    "\n",
    "hours_per_week_feat = df_data['hours_per_week'].to_numpy().reshape(-1,1)\n",
    "# print (edu_feat.shape)\n",
    "min_max_scaler_age = preprocessing.MinMaxScaler()\n",
    "hours_per_week_feat = min_max_scaler_age.fit_transform(hours_per_week_feat)\n",
    "print ('hours_per_week_feat',hours_per_week_feat.shape, min_max_scaler_age.data_min_, min_max_scaler_age.data_max_)\n",
    "\n",
    "\n",
    "\n",
    "gdp_pc_feat = df_data['gdp_pc'].to_numpy().reshape(-1,1)\n",
    "# print (edu_feat.shape)\n",
    "min_max_scaler_age = preprocessing.MinMaxScaler()\n",
    "gdp_pc_feat = min_max_scaler_age.fit_transform(gdp_pc_feat)\n",
    "print ('gdp_pc_feat',gdp_pc_feat.shape, min_max_scaler_age.data_min_, min_max_scaler_age.data_max_)\n",
    "\n",
    "\n",
    "def _income_encoder(x):\n",
    "    gender_dict = {\n",
    "        \"<=50K\":0,\n",
    "        \">50K\":1,\n",
    "    }\n",
    "    return gender_dict[x]\n",
    "income_feat = [_income_encoder(_) for _ in df_data['income_per_year'].to_list()]\n",
    "income_feat = np.array(income_feat).reshape(-1,1)\n",
    "print ('income_feat',income_feat.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _white_black_encoder(x):\n",
    "    race_dict = {\n",
    "        \"White\":0,\n",
    "        \"Black\":1,\n",
    "        \"Asian-Pac-Islander\":-1,\n",
    "        \"Amer-Indian-Eskimo\":-1,\n",
    "        \"Other\":-1\n",
    "    }\n",
    "    _feat = race_dict[x]\n",
    "    return _feat\n",
    "race_white_black_feat = [_white_black_encoder(_) for _ in df_data['race'].to_list()]\n",
    "race_white_black_feat = np.array(race_white_black_feat).reshape(-1,1)\n",
    "print ('race_white_black_feat',race_white_black_feat.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _immigrant_encoder(x):\n",
    "    if x == 'United States'.lower():\n",
    "        return 1 \n",
    "    else: \n",
    "        return 0\n",
    "country_is_native_feat = [_immigrant_encoder(_) for _ in df_data['native_country'].to_list()]\n",
    "country_is_native_feat = np.array(country_is_native_feat).reshape(-1,1)\n",
    "print ('country_is_native_feat',country_is_native_feat.shape)\n",
    "\n",
    "\n",
    "\n",
    "def _is_manager_encoder(x):\n",
    "    # professional_occupation = {'Craft-repair', 'Prof-specialty', 'Sales', \n",
    "    #                            'Other-service', 'Machine-op-inspct', \n",
    "    #                            'Transport-moving', 'Handlers-cleaners',\n",
    "    #                            'Farming-fishing', 'Tech-support', 'Protective-serv','Priv-house-serv','Armed-Forces'}\n",
    "    managerial_occupation = {'Exec-managerial', 'Adm-clerical'}\n",
    "    if x in managerial_occupation:\n",
    "        return 1 \n",
    "    else: \n",
    "        return 0\n",
    "occupation_managerial_feat = [_is_manager_encoder(_) for _ in df_data['occupation'].to_list()]\n",
    "occupation_managerial_feat = np.array(occupation_managerial_feat).reshape(-1,1)\n",
    "print ('occupation_managerial_feat',occupation_managerial_feat.shape)\n",
    "\n",
    "\n",
    "\n",
    "def _is_gov_employ_encoder(x):\n",
    "    # professional_occupation = {'Craft-repair', 'Prof-specialty', 'Sales', \n",
    "    #                            'Other-service', 'Machine-op-inspct', \n",
    "    #                            'Transport-moving', 'Handlers-cleaners',\n",
    "    #                            'Farming-fishing', 'Tech-support', 'Protective-serv','Priv-house-serv','Armed-Forces'}\n",
    "    \n",
    "    if 'gov' in x:\n",
    "        return 1 \n",
    "    else: \n",
    "        return 0\n",
    "occupation_is_gov_feat = [_is_gov_employ_encoder(_) for _ in df_data['workclass'].to_list()]\n",
    "occupation_is_gov_feat = np.array(occupation_is_gov_feat).reshape(-1,1)\n",
    "print ('occupation_is_gov_feat',occupation_is_gov_feat.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train feature/label shape: (31472, 9) (31472, 1)\n",
      "Dev. feature/label shape: (6744, 9) (6744, 1)\n",
      "Test feature/label shape: (6745, 9) (6745, 1)\n",
      "saved data matrix to /Users/xingzhiguo/Documents/git_project/NN-verification/cache/np-adult-data-rs=0.pkl\n",
      "Train feature/label shape: (31472, 9) (31472, 1)\n",
      "Dev. feature/label shape: (6744, 9) (6744, 1)\n",
      "Test feature/label shape: (6745, 9) (6745, 1)\n",
      "saved data matrix to /Users/xingzhiguo/Documents/git_project/NN-verification/cache/np-adult-data-rs=1.pkl\n",
      "Train feature/label shape: (31472, 9) (31472, 1)\n",
      "Dev. feature/label shape: (6744, 9) (6744, 1)\n",
      "Test feature/label shape: (6745, 9) (6745, 1)\n",
      "saved data matrix to /Users/xingzhiguo/Documents/git_project/NN-verification/cache/np-adult-data-rs=2.pkl\n"
     ]
    }
   ],
   "source": [
    "def split_set(np_data,train_ratio, RS):\n",
    "    \"\"\"Split feature-label matrix into train/dev/test\"\"\"\n",
    "    X = np_data[:,:-1].astype(float)\n",
    "    Y = np_data[:,-1].astype(int).reshape(-1,1)\n",
    "    X_train, X_rest, y_train, y_rest = train_test_split(X, Y, test_size=(1.0-train_ratio), random_state=RS)\n",
    "    X_dev, X_test, y_dev, y_test = train_test_split(X_rest, y_rest, test_size=0.5, random_state=RS)\n",
    "    return X_train, y_train, X_dev, y_dev, X_test, y_test\n",
    "\n",
    "# input_feature_list = [age_feat, edu_feat, capital_gain_feat, capital_loss_feat ,sex_feat, hours_per_week_feat, gdp_pc_feat, race_feat]\n",
    "input_feature_list = [age_feat, edu_feat, hours_per_week_feat, sex_feat, race_feat]\n",
    "Y = income_feat\n",
    "X = np.hstack(input_feature_list)\n",
    "\n",
    "data_set = np.hstack([X,Y])\n",
    "for random_seed in range(3):\n",
    "    RS = np.random.RandomState(random_seed)\n",
    "    # train/dev/test set\n",
    "    train_ratio = 0.7 # dev and test share the rest\n",
    "    X_train, y_train, X_dev, y_dev, X_test, y_test = split_set(data_set,train_ratio, RS)\n",
    "    print ('Train feature/label shape:',X_train.shape, y_train.shape)\n",
    "    print ('Dev. feature/label shape:',X_dev.shape, y_dev.shape)\n",
    "    print ('Test feature/label shape:',X_test.shape, y_test.shape)\n",
    "\n",
    "    data_output = {\n",
    "        \"X_train\":X_train,\n",
    "        \"y_train\":y_train,\n",
    "        \"X_dev\":X_dev,\n",
    "        \"y_dev\":y_dev,\n",
    "        \"X_test\":X_test,\n",
    "        \"y_test\":y_test,\n",
    "    }\n",
    "    cache_path = '/Users/xingzhiguo/Documents/git_project/NN-verification/cache'\n",
    "    cache_file_path = os_join(cache_path,f'np-adult-data-rs={random_seed}.pkl')\n",
    "    with open (cache_file_path,'wb') as f:\n",
    "        pickle.dump(data_output,f)\n",
    "    print (f'saved data matrix to {cache_file_path}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train feature/label shape: (30121, 8) (30121, 1)\n",
      "Dev. feature/label shape: (6455, 8) (6455, 1)\n",
      "Test feature/label shape: (6455, 8) (6455, 1)\n",
      "saved data matrix to /Users/xingzhiguo/Documents/git_project/NN-verification/cache/np-adult-data-v2-rs=0.pkl\n",
      "Train feature/label shape: (30121, 8) (30121, 1)\n",
      "Dev. feature/label shape: (6455, 8) (6455, 1)\n",
      "Test feature/label shape: (6455, 8) (6455, 1)\n",
      "saved data matrix to /Users/xingzhiguo/Documents/git_project/NN-verification/cache/np-adult-data-v2-rs=1.pkl\n",
      "Train feature/label shape: (30121, 8) (30121, 1)\n",
      "Dev. feature/label shape: (6455, 8) (6455, 1)\n",
      "Test feature/label shape: (6455, 8) (6455, 1)\n",
      "saved data matrix to /Users/xingzhiguo/Documents/git_project/NN-verification/cache/np-adult-data-v2-rs=2.pkl\n"
     ]
    }
   ],
   "source": [
    "def split_set(np_data,train_ratio, RS):\n",
    "    \"\"\"Split feature-label matrix into train/dev/test\"\"\"\n",
    "    X = np_data[:,:-1].astype(float)\n",
    "    Y = np_data[:,-1].astype(int).reshape(-1,1)\n",
    "    X_train, X_rest, y_train, y_rest = train_test_split(X, Y, test_size=(1.0-train_ratio), random_state=RS)\n",
    "    X_dev, X_test, y_dev, y_test = train_test_split(X_rest, y_rest, test_size=0.5, random_state=RS)\n",
    "    return X_train, y_train, X_dev, y_dev, X_test, y_test\n",
    "\n",
    "# input_feature_list = [age_feat, edu_feat, capital_gain_feat, capital_loss_feat ,sex_feat, hours_per_week_feat, gdp_pc_feat, race_feat]\n",
    "input_feature_list = [age_feat, edu_feat, hours_per_week_feat, sex_feat, race_white_black_feat, country_is_native_feat, occupation_managerial_feat, occupation_is_gov_feat]\n",
    "Y = income_feat\n",
    "X = np.hstack(input_feature_list)\n",
    "\n",
    "# keep only white black \n",
    "\n",
    "selected_index = np.where(X[:,4]!=-1)[0]\n",
    "X = X[selected_index,:]\n",
    "Y = Y[selected_index,:]\n",
    "\n",
    "\n",
    "data_set = np.hstack([X,Y])\n",
    "for random_seed in range(3):\n",
    "    RS = np.random.RandomState(random_seed)\n",
    "    # train/dev/test set\n",
    "    train_ratio = 0.7 # dev and test share the rest\n",
    "    X_train, y_train, X_dev, y_dev, X_test, y_test = split_set(data_set,train_ratio, RS)\n",
    "    print ('Train feature/label shape:',X_train.shape, y_train.shape)\n",
    "    print ('Dev. feature/label shape:',X_dev.shape, y_dev.shape)\n",
    "    print ('Test feature/label shape:',X_test.shape, y_test.shape)\n",
    "\n",
    "    data_output = {\n",
    "        \"X_train\":X_train,\n",
    "        \"y_train\":y_train,\n",
    "        \"X_dev\":X_dev,\n",
    "        \"y_dev\":y_dev,\n",
    "        \"X_test\":X_test,\n",
    "        \"y_test\":y_test,\n",
    "    }\n",
    "    cache_path = '/Users/xingzhiguo/Documents/git_project/NN-verification/cache'\n",
    "    cache_file_path = os_join(cache_path,f'np-adult-data-v2-rs={random_seed}.pkl')\n",
    "    with open (cache_file_path,'wb') as f:\n",
    "        pickle.dump(data_output,f)\n",
    "    print (f'saved data matrix to {cache_file_path}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3]\n",
      " [ 4  1  6  7]\n",
      " [ 8  1 10 11]\n",
      " [12 13 14 15]]\n",
      "[[ 0  1  2  3]\n",
      " [ 4  1  6  7]\n",
      " [ 8  1 10 11]\n",
      " [12 13 14 15]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def stratify_permute_row_inplace(a, reference_col_ind, permute_col_ind, RS):\n",
    "    ref_col_vals = a[:,reference_col_ind]\n",
    "    unique_val_in_ref_col = np.unique(ref_col_vals)\n",
    "\n",
    "    for _val in unique_val_in_ref_col:\n",
    "        row_group_index = np.where( (ref_col_vals==_val).all(1), 1, 0).nonzero()[0]\n",
    "        #print (0, _val, row_group_index)\n",
    "        _permute_col_of_row = a[np.ix_(row_group_index, permute_col_ind)]\n",
    "        #print (1,_permute_col_of_row)\n",
    "        permuted_permute_col_of_row = RS.permutation(_permute_col_of_row)\n",
    "        #print (2,permuted_permute_col_of_row)\n",
    "        a[np.ix_(row_group_index, permute_col_ind)] = permuted_permute_col_of_row\n",
    "        \n",
    "a = np.arange(16).reshape(4,4)\n",
    "a[1,1] = 1\n",
    "a[2,1] = 1\n",
    "\n",
    "random_seed = 4\n",
    "RS = np.random.RandomState(random_seed)\n",
    "\n",
    "print (a)\n",
    "reference_col_ind = []\n",
    "permute_col_ind = np.array([0,1,2,3])\n",
    "\n",
    "stratify_permute_row_inplace(a, reference_col_ind, permute_col_ind, RS)\n",
    "print (a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, False])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(16).reshape(4,4)\n",
    "a[1,1] = 1\n",
    "a[2,1] = 1\n",
    "\n",
    "a[:,1]==1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(a[:,1]==1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2],\n",
       "       [ 1,  6],\n",
       "       [ 1, 10],\n",
       "       [13, 14]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,[1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "db332fe5bc5ebb4742063ca4b87cff3f471d2a090567720d31fef0635138e626"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
